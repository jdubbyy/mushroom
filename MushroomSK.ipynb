{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\CodingProjects\\Mushroom\\UCIrvine_Mushroom_Data\\agaricus-lepiota.data', header=None, na_values = '?')\n",
    "\n",
    "schema = ['Edible', 'Cap Shape', 'Cap Surface', 'Cap Color', 'Bruises?', 'Odor',\n",
    "          'Gill Attachment', 'Gill Spacing', 'Gill Size', 'Gill Color', 'Stalk Shape', 'Stalk Root',\n",
    "          'Stalk Surface Above Ring', 'Stalk Surface Below Ring', 'Stalk Color Above Ring', 'Stalk Color Below Ring',\n",
    "          'Veil Type', 'Veil Color', 'Ring Number', 'Ring Type', 'Spore Print Color', 'Population', 'Habitat']\n",
    "df.columns = schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the information gain of each attribute\n",
    "\n",
    "##### Using the Scikit-learn library, the information gain for each attribute can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for Odor: 0.906075\n",
      "Information Gain for Spore Print Color: 0.480705\n",
      "Information Gain for Gill Color: 0.416978\n",
      "Information Gain for Ring Type: 0.318022\n",
      "Information Gain for Stalk Surface Above Ring: 0.284726\n",
      "Information Gain for Stalk Surface Below Ring: 0.271894\n",
      "Information Gain for Stalk Color Above Ring: 0.253845\n",
      "Information Gain for Stalk Color Below Ring: 0.241416\n",
      "Information Gain for Gill Size: 0.230154\n",
      "Information Gain for Population: 0.201958\n",
      "Information Gain for Bruises?: 0.192379\n",
      "Information Gain for Stalk Root: 0.134818\n",
      "Information Gain for Gill Spacing: 0.100883\n",
      "Information Gain for Cap Shape: 0.048797\n",
      "Information Gain for Ring Number: 0.038453\n",
      "Information Gain for Cap Color: 0.036049\n",
      "Information Gain for Cap Surface: 0.028590\n",
      "Information Gain for Veil Color: 0.023817\n",
      "Information Gain for Gill Attachment: 0.014165\n",
      "Information Gain for Stalk Shape: 0.007517\n",
      "Information Gain for Veil Type: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Prepare the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(df['Edible'])\n",
    "\n",
    "# Get the list of original features\n",
    "original_features = schema[1:-1]\n",
    "\n",
    "# Calculate mutual information for each feature individually\n",
    "mi_scores = {}\n",
    "for feature in original_features:\n",
    "    # Convert categorical feature to numerical using LabelEncoder\n",
    "    X_feature = df[feature].copy()\n",
    "    le = LabelEncoder()\n",
    "    X_feature_encoded = le.fit_transform(X_feature).reshape(-1, 1)\n",
    "    \n",
    "    # Calculate mutual information\n",
    "    # Setting discrete_features=True is important for categorical variables\n",
    "    mi = mutual_info_classif(X_feature_encoded, Y, discrete_features=True)[0]\n",
    "    #divide by log(2) to adjust the log base to 2 instead of e\n",
    "    mi_scores[feature] = mi / np.log(2)\n",
    "\n",
    "# Sort features by mutual information score\n",
    "sorted_mi = sorted(mi_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print results\n",
    "for feature, score in sorted_mi:\n",
    "    print(f'Information Gain for {feature}: {score:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The calculated information gain from each attribute matches that of the outputs of the manual approach in Mushroom.ipynb!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the entropy of the parent set\n",
    "\n",
    "##### Using Scikit-learn again, the entropy of the parent set can be calculated to further verify the output of the Mushroom.ipynb approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy at parent node 0: 0.9990678968724604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_feature_encoded, Y)\n",
    "\n",
    "# Access the tree structure\n",
    "tree_ = clf.tree_\n",
    "\n",
    "# Let's say you want the entropy of the root node (index 0)\n",
    "parent_node_index = 0\n",
    "\n",
    "# Get the entropy\n",
    "entropy_parent = tree_.impurity[parent_node_index]\n",
    "\n",
    "print(f\"Entropy at parent node {parent_node_index}: {entropy_parent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The parent set entropy also matches that of Mushroom.ipynb! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mushroom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
